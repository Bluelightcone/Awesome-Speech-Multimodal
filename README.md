# Awesome-Speech-Multimodal
| Paper                                                                                                   | Method | Venue                      | Code    |
|---------------------------------------------------------------------------------------------------------|--------|----------------------------|---------|
| [ViLReF: An Expert Knowledge Enabled Vision-Language Retinal Foundation Model](https://arxiv.org/abs/2408.10894) | - | Tip 2024  | [Github](https://github.com/T6Yang/ViLReF) |
| Positive-Aware Lesion Detection Network with Cross-scale Feature Pyramid for OCT Images | -  | Miccai 2020 | -  |
| [You Only Speak Once to See](https://arxiv.org/abs/2409.18372) | - | - |
| Speech-to-Image Creation Using Jina | - | - |
| [VITA-1.5: Towards GPT-4o Level Real-Time Vision and Speech Interaction](https://arxiv.org/pdf/2501.01957)  | -      | arXiv Jan 2025  | [Github](https://github.com/VITA-MLLM/VITA) |
| [Viiat-Hand: A Reach-and-Grasp Restoration System Integrating Voice Interaction, Computer Vision, Auditory and Tactile Feedback for Non-Sighted Amputees](https://ieeexplore.ieee.org/document/10643668)  | - |  IEEE Robotics and Automation Letters 2024 ｜ -  |
| Chimera: Effectively Modeling Multivariate Time Series with 2-Dimensional State Space Models | - | NeurIPS 2024 | - |
| [A Comprehensive Survey on Diffusion Models and Their Applications](https://arxiv.org/abs/2408.10207)   | -      | July 2024          | -  |
| [SAV-SE: Scene-aware Audio-Visual Speech Enhancement with Selective State Space Model](https://arxiv.org/abs/2411.07751) | -      | arXiv 12 Nov 2024   | - |
| [A Comprehensive Survey on Applications of Transformers for Deep Learning Tasks](https://arxiv.org/abs/2306.07303) | -      | Elsevier 2023  | [Github](https://github.com/mangye16/ReID-Survey)|
| [DiM-Gestor: Co-Speech Gesture Generation with Adaptive Layer Normalization Mamba-2](https://arxiv.org/abs/2411.16729) | -     | arXiv Nov 2024   | - |
| Radiology report generation with a learned knowledge base and multi-modal alignment | -      | MIA 2023 | [GitHub](https://github.com/LX-doctorAI1/M2KT) |
| [Image, Text, and Speech Data Augmentation using Multimodal LLMs for Deep Learning: A Survey](https://arxiv.org/abs/2501.18648)     | -      | Jan 2025   | [Github](https://github.com/wsuagrobotics/data-aug-multi-modal-llm)   |
| [Mini-Omni2: Towards Open-source GPT-4o with Vision, Speech and Duplex Capabilities](https://arxiv.org/abs/2410.11190)       | -      | arXiv Nov 2024          | [Github](https://github.com/gpt-omni/mini-omni2)       |
| [Mixture-of-Transformers: A Sparse and Scalable Architecture for Multi-Modal Foundation Models](https://arxiv.org/abs/2411.04996)| -      | arXiv Nov 2024 | -    |
| [Mamba in Speech: Towards an Alternative to Self-Attention](https://arxiv.org/abs/2405.12609)| -   |  arXiv Ovt 2024  | [Github](https://github.com/Tonyyouyou/Mamba-in-Speech)  |
| [video-SALMONN: Speech-Enhanced Audio-Visual Large Language Models](https://arxiv.org/html/2406.15704v1/) | - | arXiv Jun 2024 |  [Github](https://github.com/bytedance/SALMONN/)  |
| [Graph Convolutions Enrich the Self-Attention in Transformers!](https://arxiv.org/pdf/2312.04234) | - | NeurIPS 2024 | [Github](https://github.com/jeongwhanchoi/GFSA) |
| [VASA-1: Lifelike Audio-Driven Talking Faces Generated in Real Time](https://arxiv.org/abs/2404.10667)   |   -   |   	NeurIPS 2024 (Oral) | - |
|Mixture-of-Mamba: Enhancing Multi-Modal State-Space Models with Modality-Aware Sparsity| - | arXiv Jan 2025| [Github](https://github.com/weixin-liang/mixture-of-mamba)|
| [Theory, Analysis, and Best Practices for Sigmoid Self-Attention](https://arxiv.org/abs/2409.04431) | - | arXiv Jan 2025 | [Github](https://github.com/apple/ml-sigmoid-attention)|
| [Sonic: Shifting Focus to Global Audio Perception in Portrait Animation](https://arxiv.org/pdf/2411.16331) | - | Nov 2024 |[Github](https://github.com/jixiaozhong/Sonic) |
| [ConvoFusion: Multi-Modal Conversational Diffusion for Co-Speech Gesture Synthesis](https://arxiv.org/abs/2403.17936) | - | CVPR 2024 | [Github](https://github.com/m-hamza-mughal/convofusion)|
| [JambaTalk: Speech-Driven 3D Talking Head Generation Based on Hybrid Transformer-Mamba Model](https://arxiv.org/abs/2408.01627) | - | Aug 2024  | - |
| [Latent Semantic and Disentangled Attention](https://ieeexplore.ieee.org/document/10607968) | - |TPAMI 2024 | - |
| [KMTalk: Speech-Driven 3D Facial Animation with Key Motion Embedding](https://arxiv.org/abs/2409.01113)   | -      |  ECCV 2024        |[GitHub](https://github.com/ffxzh/KMTalk)      |
|Mamba-360: Survey of State Space Models as Transformer Alternative for Long Sequence Modelling: Methods, Applications, and Challenges| arXiv april 2024 | [GitHub](https://github.com/badripatro/mamba360) |
| [AudioPaLM: A Large Language Model That Can Speak and Listen](https://arxiv.org/abs/2407.14474)      | -      | 	arXiv Jun 2023          | -  |
| [VASA-1: Lifelike Audio-Driven Talking Faces Generated in Real Time](https://arxiv.org/abs/2404.10667) | -  | NeurIPS 2024 (Oral) | - |
| Chimera: Effectively Modeling Multivariate Time Series with 2-Dimensional State Space Models | NeurIPS 2024  | - |
| [INFP: Audio-Driven Interactive Head Generation in Dyadic Conversations](https://grisoon.github.io/INFP/) | - | Dec 2024 | - |
| [Media2Face: Co-speech Facial Animation Generation With Multi-Modality Guidance](https://arxiv.org/abs/2401.15687)  | - |  Jan 2025  |  - |
| [Toward Large-scale Spiking Neural Networks: A Comprehensive Survey and Future Directions](https://arxiv.org/abs/2409.02111) | - | Aug 2024 | - |
| [Learn2Talk: 3D Talking Face Learns from 2D Talking Face](https://arxiv.org/abs/2404.12888) | - | TVCG 2024 |  ｜ - ｜
| [Ola: Pushing the Frontiers of Omni-Modal Language Model with Progressive Modality Alignment](https://arxiv.org/abs/2502.04328) | - | ACM MM 2024 | - |
| [TRAMBA: A Hybrid Transformer and Mamba Architecture for Practical Audio and Bone Conduction Speech Super Resolution and Enhancement on Mobile and Wearable Platforms](https://dl.acm.org/doi/10.1145/3699757) | - | ACM UbiComp 2024 ｜ - ｜
| [Preference Tuning with Human Feedback on Language, Speech, and Vision Tasks: A Survey](https://arxiv.org/abs/2409.11564) | - | arXiv Nov 2024 | -  |
| [Let SSMs be ConvNets: State-space Modeling with Optimal Tensor Contractions](https://openreview.net/forum?id=PkpNRmBZ32) | - | ICLR 2025 Spotlight | - |
| [video-SALMONN: Speech-Enhanced Audio-Visual Large Language Models](https://arxiv.org/abs/2406.15704) | - | ICML 2024 | [Github](https://github.com/bytedance/SALMONN/) |
| [T3M: Text Guided 3D Human Motion Synthesis from Speech](https://aclanthology.org/2024.findings-naacl.74/) | - | 2024.findings-naacl | [Github](https://github.com/Gloria2tt/T3M) |
| [MS2Mesh-XR: Multi-modal Sketch-to-Mesh Generation in XR Environments](https://arxiv.org/abs/2412.09008) | - | 	IEEE AIxVR 2025 | - |
| [Quilt-1M: One Million Image-Text Pairs for Histopathology](https://proceedings.neurips.cc/paper_files/paper/2023/file/775ec578876fa6812c062644964b9870-Paper-Datasets_and_Benchmarks.pdf) | - | NeurIPS 2023 Track on Datasets and Benchmarks |  [Github](https://github.com/wisdomikezogwo/quilt1m) |
| [Quilt-LLaVA: Visual Instruction Tuning by Extracting Localized Narratives from Open-Source Histopathology Videos](https://openaccess.thecvf.com/content/CVPR2024/supplemental/Seyfioglu_Quilt-LLaVA_Visual_Instruction_CVPR_2024_supplemental.pdf) | - | CVPR 2024 | [Github](https://github.com/aldraus/quilt-llava) |
| [Parameter-Efficient Fine-Tuning for Medical Image Analysis: The Missed Opportunity](https://openreview.net/forum?id=LVRhXa0q5r) | - | MIDL 2024 Oral | -  ｜
| [Improving Medical Speech-to-Text Accuracy using Vision-Language Pre-training Models](https://ieeexplore.ieee.org/document/10372102) | - | IEEE Journal of Biomedical and Health Informatics  2024 | - |
| [MixCon: A Hybrid Architecture for Efficient and Adaptive Sequence Modeling](https://zhouchenlin.github.io/Publications/2024-ECAI-MixCon.pdf) | - | ECAI 2024 ｜ -  |
| [Multimodal Latent Language Modeling with Next-Token Diffusion](https://arxiv.org/abs/2412.08635) | - | arXiv Dec 2024  | [Github](https://github.com/microsoft/unilm/tree/master/LatentLM) |
| [DLF: Disentangled-Language-Focused Multimodal Sentiment Analysis](https://arxiv.org/abs/2412.12225) | - | AAAI 2025  |  [Github](https://github.com/pwang322/DLF) |
| [EchoMimicV2: Towards Striking, Simplified, and Semi-Body Human Animation](https://arxiv.org/abs/2411.10061) | - | Nov 2024 | [Github](https://github.com/antgroup/echomimic) |
| [Look Hear: Gaze Prediction for Speech-directed Human Attention](https://arxiv.org/abs/2407.19605) | - | ECCV 2024 | [Github](https://github.com/cvlab-stonybrook/ART) |
| [Large Concept Models: Language Modeling in a Sentence Representation Space](https://arxiv.org/abs/2412.08821) | - | arXiv Dec 2024 | [Github (https://github.com/facebookresearch/large_concept_model) |
| []() | - |[Github]() |
| [Hallo2: Long-Duration and High-Resolution Audio-Driven Portrait Image Animation](https://arxiv.org/abs/2410.07718) | - | ICLR 2025 | [Github](https://github.com/fudan-generative-vision/hallo2) |
| [MAVD: The First Open Large-Scale Mandarin Audio-Visual Dataset with Depth Information](https://arxiv.org/abs/2306.02263) | - | arXiv Jun 2023 | [Github](https://github.com/SpringHuo/MAVD) |
| [Efficient Region-Aware Neural Radiance Fields for High-Fidelity Talking Portrait Synthesis](https://arxiv.org/abs/2307.09323) | - | ICCV 2023 | [Githun](https://github.com/Fictionarry/ER-NeRF)
