# Awesome-Speech-Multimodal
| Paper                                                                                                   | Method | Venue                      | Code    |
|---------------------------------------------------------------------------------------------------------|--------|----------------------------|---------|
| [ViLReF: An Expert Knowledge Enabled Vision-Language Retinal Foundation Model](https://arxiv.org/abs/2408.10894) | - | Tip 2024  | [Github](https://github.com/T6Yang/ViLReF) |
| [Positive-Aware Lesion Detection Network with Cross-scale Feature Pyramid for OCT Images](https://www.researchgate.net/publication/346068882_Positive-Aware_Lesion_Detection_Network_with_Cross-scale_Feature_Pyramid_for_OCT_Images) | -  | Miccai 2020 | -  |
| [You Only Speak Once to See](https://arxiv.org/abs/2409.18372) | - | - |
| [Speech-to-Image Creation Using Jina](https://jina.ai/news/speech-to-image-generation/) | - | Oct 2022 | - |
| [VITA-1.5: Towards GPT-4o Level Real-Time Vision and Speech Interaction](https://arxiv.org/pdf/2501.01957)  | -      | arXiv Jan 2025  | [Github](https://github.com/VITA-MLLM/VITA) |
| [Viiat-Hand: A Reach-and-Grasp Restoration System Integrating Voice Interaction, Computer Vision, Auditory and Tactile Feedback for Non-Sighted Amputees](https://ieeexplore.ieee.org/document/10643668)  | - |  IEEE Robotics and Automation Letters 2024 ｜ -  |
| [Chimera: Effectively Modeling Multivariate Time Series with 2-Dimensional State Space Models](https://openreview.net/forum?id=ncYGjx2vnE&noteId=SB0dLuJeL7) | - | NeurIPS 2024 | - |
| [A Comprehensive Survey on Diffusion Models and Their Applications](https://arxiv.org/abs/2408.10207)   | -      | July 2024          | -  |
| [SAV-SE: Scene-aware Audio-Visual Speech Enhancement with Selective State Space Model](https://arxiv.org/abs/2411.07751) | -      | arXiv 12 Nov 2024   | - |
| [A Comprehensive Survey on Applications of Transformers for Deep Learning Tasks](https://arxiv.org/abs/2306.07303) | -      | Elsevier 2023  | [Github](https://github.com/mangye16/ReID-Survey)|
| [DiM-Gestor: Co-Speech Gesture Generation with Adaptive Layer Normalization Mamba-2](https://arxiv.org/abs/2411.16729) | -     | arXiv Nov 2024   | - |
| [Image, Text, and Speech Data Augmentation using Multimodal LLMs for Deep Learning: A Survey](https://arxiv.org/abs/2501.18648)     | -      | Jan 2025   | [Github](https://github.com/wsuagrobotics/data-aug-multi-modal-llm)   |
| [Mini-Omni2: Towards Open-source GPT-4o with Vision, Speech and Duplex Capabilities](https://arxiv.org/abs/2410.11190)       | -      | arXiv Nov 2024          | [Github](https://github.com/gpt-omni/mini-omni2)  |
| [Mixture-of-Transformers: A Sparse and Scalable Architecture for Multi-Modal Foundation Models](https://arxiv.org/abs/2411.04996)| -    | arXiv Nov 2024 | -    |
| [Mamba in Speech: Towards an Alternative to Self-Attention](https://arxiv.org/abs/2405.12609)| -   |  arXiv Ovt 2024  | [Github](https://github.com/Tonyyouyou/Mamba-in-Speech)  |
| [video-SALMONN: Speech-Enhanced Audio-Visual Large Language Models](https://arxiv.org/html/2406.15704v1/) | - | arXiv Jun 2024 |  [Github](https://github.com/bytedance/SALMONN/)  |
| [Graph Convolutions Enrich the Self-Attention in Transformers!](https://arxiv.org/pdf/2312.04234) | - | NeurIPS 2024 | [Github](https://github.com/jeongwhanchoi/GFSA) |
| [VASA-1: Lifelike Audio-Driven Talking Faces Generated in Real Time](https://arxiv.org/abs/2404.10667)   |   -   |   	NeurIPS 2024 (Oral) | - |
| [Mixture-of-Mamba: Enhancing Multi-Modal State-Space Models with Modality-Aware Sparsity](https://arxiv.org/abs/2501.16295)| - | arXiv Jan 2025| [Github](https://github.com/weixin-liang/mixture-of-mamba)|
| [Theory, Analysis, and Best Practices for Sigmoid Self-Attention](https://arxiv.org/abs/2409.04431) | - | arXiv Jan 2025 | [Github](https://github.com/apple/ml-sigmoid-attention)|
| [Sonic: Shifting Focus to Global Audio Perception in Portrait Animation](https://arxiv.org/pdf/2411.16331) | - | Nov 2024 |[Github](https://github.com/jixiaozhong/Sonic) |
| [ConvoFusion: Multi-Modal Conversational Diffusion for Co-Speech Gesture Synthesis](https://arxiv.org/abs/2403.17936) | - | CVPR 2024 | [Github](https://github.com/m-hamza-mughal/convofusion)|
| [JambaTalk: Speech-Driven 3D Talking Head Generation Based on Hybrid Transformer-Mamba Model](https://arxiv.org/abs/2408.01627) | - | Aug 2024  | - |
| [Latent Semantic and Disentangled Attention](https://ieeexplore.ieee.org/document/10607968) | - |TPAMI 2024 | - |
| [KMTalk: Speech-Driven 3D Facial Animation with Key Motion Embedding](https://arxiv.org/abs/2409.01113)   | -      |  ECCV 2024        |[GitHub](https://github.com/ffxzh/KMTalk)      |
| [Mamba-360: Survey of State Space Models as Transformer Alternative for Long Sequence Modelling: Methods, Applications, and Challenges](https://arxiv.org/abs/2404.16112)| arXiv april 2024 | [GitHub](https://github.com/badripatro/mamba360) |
| [AudioPaLM: A Large Language Model That Can Speak and Listen](https://arxiv.org/abs/2407.14474)      | -      | 	arXiv Jun 2023          | -  |
| [VASA-1: Lifelike Audio-Driven Talking Faces Generated in Real Time](https://arxiv.org/abs/2404.10667) | -  | NeurIPS 2024 (Oral) | - |
| Chimera: Effectively Modeling Multivariate Time Series with 2-Dimensional State Space Models | NeurIPS 2024  | - |
| [INFP: Audio-Driven Interactive Head Generation in Dyadic Conversations](https://grisoon.github.io/INFP/) | - | Dec 2024 | - |
| [Media2Face: Co-speech Facial Animation Generation With Multi-Modality Guidance](https://arxiv.org/abs/2401.15687)  | - |  Jan 2025  |  - |
| [Toward Large-scale Spiking Neural Networks: A Comprehensive Survey and Future Directions](https://arxiv.org/abs/2409.02111) | - | Aug 2024 | - |
| [Learn2Talk: 3D Talking Face Learns from 2D Talking Face](https://arxiv.org/abs/2404.12888) | - | TVCG 2024 |  ｜ - ｜
| [Ola: Pushing the Frontiers of Omni-Modal Language Model with Progressive Modality Alignment](https://arxiv.org/abs/2502.04328) | - | ACM MM 2024 | - |
| [TRAMBA: A Hybrid Transformer and Mamba Architecture for Practical Audio and Bone Conduction Speech Super Resolution and Enhancement on Mobile and Wearable Platforms](https://dl.acm.org/doi/10.1145/3699757
        
        ) | - | ACM UbiComp 2024 ｜ - ｜
| [Preference Tuning with Human Feedback on Language, Speech, and Vision Tasks: A Survey](https://arxiv.org/abs/2409.11564) | - | arXiv Nov 2024 | -  |
| [Let SSMs be ConvNets: State-space Modeling with Optimal Tensor Contractions](https://openreview.net/forum?id=PkpNRmBZ32) | - | ICLR 2025 Spotlight | - |
| [video-SALMONN: Speech-Enhanced Audio-Visual Large Language Models](https://arxiv.org/abs/2406.15704) | - | ICML 2024 | [Github](https://github.com/bytedance/SALMONN/) |
| [T3M: Text Guided 3D Human Motion Synthesis from Speech](https://aclanthology.org/2024.findings-naacl.74/) | - | 2024.findings-naacl | [Github](https://github.com/Gloria2tt/T3M) |
| [MS2Mesh-XR: Multi-modal Sketch-to-Mesh Generation in XR Environments](https://arxiv.org/abs/2412.09008) | - | 	IEEE AIxVR 2025 | - |
| [Quilt-1M: One Million Image-Text Pairs for Histopathology](https://proceedings.neurips.cc/paper_files/paper/2023/file/775ec578876fa6812c062644964b9870-Paper-Datasets_and_Benchmarks.pdf) | - | NeurIPS 2023 Track on Datasets and Benchmarks |  [Github](https://github.com/wisdomikezogwo/quilt1m) |
| [Quilt-LLaVA: Visual Instruction Tuning by Extracting Localized Narratives from Open-Source Histopathology Videos](https://openaccess.thecvf.com/content/CVPR2024/supplemental/Seyfioglu_Quilt-LLaVA_Visual_Instruction_CVPR_2024_supplemental.pdf) | - | CVPR 2024 | [Github](https://github.com/aldraus/quilt-llava) |
| [Parameter-Efficient Fine-Tuning for Medical Image Analysis: The Missed Opportunity](https://openreview.net/forum?id=LVRhXa0q5r) | - | MIDL 2024 Oral | -  ｜
| [Improving Medical Speech-to-Text Accuracy using Vision-Language Pre-training Models](https://ieeexplore.ieee.org/document/10372102) | - | IEEE Journal of Biomedical and Health Informatics  2024 | - |
| [MixCon: A Hybrid Architecture for Efficient and Adaptive Sequence Modeling](https://zhouchenlin.github.io/Publications/2024-ECAI-MixCon.pdf) | - | ECAI 2024 ｜ -  |
| [Multimodal Latent Language Modeling with Next-Token Diffusion](https://arxiv.org/abs/2412.08635) | - | arXiv Dec 2024  | [Github](https://github.com/microsoft/unilm/tree/master/LatentLM) |
| [DLF: Disentangled-Language-Focused Multimodal Sentiment Analysis](https://arxiv.org/abs/2412.12225) | - | AAAI 2025  |  [Github](https://github.com/pwang322/DLF) |
| [EchoMimicV2: Towards Striking, Simplified, and Semi-Body Human Animation](https://arxiv.org/abs/2411.10061) | - | Nov 2024 | [Github](https://github.com/antgroup/echomimic) |
| [Look Hear: Gaze Prediction for Speech-directed Human Attention](https://arxiv.org/abs/2407.19605) | - | ECCV 2024 | [Github](https://github.com/cvlab-stonybrook/ART) |
| [Large Concept Models: Language Modeling in a Sentence Representation Space](https://arxiv.org/abs/2412.08821) | - | arXiv Dec 2024 | [Github](https://github.com/facebookresearch/large_concept_model) |
| [S2IGAN: Speech-to-Image Generation via Adversarial Learning](https://arxiv.org/abs/2005.06968) | - | Interspeech2020 |[Github](https://github.com/NVIDIA/tacotron2) |
| [Hallo2: Long-Duration and High-Resolution Audio-Driven Portrait Image Animation](https://arxiv.org/abs/2410.07718) | - | ICLR 2025 | [Github](https://github.com/fudan-generative-vision/hallo2) |
| [MAVD: The First Open Large-Scale Mandarin Audio-Visual Dataset with Depth Information](https://arxiv.org/abs/2306.02263) | - | arXiv Jun 2023 | [Github](https://github.com/SpringHuo/MAVD) |
| [Efficient Region-Aware Neural Radiance Fields for High-Fidelity Talking Portrait Synthesis](https://arxiv.org/abs/2307.09323) | - | ICCV 2023 | [Github](https://github.com/Fictionarry/ER-NeRF)
| [SQ-VAE: Variational Bayes on Discrete Representation with Self-annealed Stochastic Quantization](https://arxiv.org/abs/2205.07547) | - | ICML 2022 | [Github](https://github.com/sony/sqvae) |
| [Deep Compression of Pre-trained Transformer Models](https://openreview.net/forum?id=EZQnauHn-77) | - | NeurIPS 2022 | -  |
| [Can Language Models Learn to Listen?](https://arxiv.org/abs/2308.10897) | - | 	ICCV 2023 | [Github](https://github.com/sanjayss34/lm-listener) |
| [Text with Knowledge Graph Augmented Transformer for Video Captioning](https://arxiv.org/abs/2303.12423) | - |  CVPR2023 | - |
| [From Audio to Photoreal Embodiment: Synthesizing Humans in Conversations ](https://openaccess.thecvf.com/content/CVPR2024/papers/Ng_From_Audio_to_Photoreal_Embodiment_Synthesizing_Humans_in_Conversations_CVPR_2024_paper.pdf) | - | CVPR 2024 | [Github](https://github.com/facebookresearch/audio2photoreal/) |
| [Masking Modalities for Cross-modal Video Retrieva](https://arxiv.org/abs/2111.01300) |- |  WACV 2022 | - |
| [Audio-Driven Co-Speech Gesture Video Generation](https://arxiv.org/abs/2212.02350) | - | NeurIPS 2022 Spotlight | [Github](https://github.com/alvinliu0/ANGIE) |
| [FaceFormer: Speech-Driven 3D Facial Animation with Transformers](https://arxiv.org/abs/2112.05329) | - | CVPR 2022 | [Github](https://github.com/EvelynFan/FaceFormer) |
| [AIfES: A Next-Generation Edge AI Framework](https://ieeexplore.ieee.org/document/10403985) | - | TPAMI 2024 | -  |
| [Masked Modeling for Self-supervised Representation Learning on Vision and Beyond](https://arxiv.org/abs/2401.00897) | - | arxiv Jan 2024  | [Github](https://github.com/Lupin1998/Awesome-MIM) |
| [HeadStudio: Text to Animatable Head Avatars with 3D Gaussian Splatting](https://arxiv.org/abs/2402.06149) | - | ECCV 2024 | [Github](https://github.com/ZhenglinZhou/HeadStudio) |
| [VLOGGER: Multimodal Diffusion for Embodied Avatar Synthesis](https://arxiv.org/abs/2403.08764) | - | - |
| [Batched Low-Rank Adaptation of Foundation Models](https://openreview.net/forum?id=w4abltTZ2f) | - | ICLR 2024 oral |  - |
| [i-Code Studio: A Configurable and Composable Framework for Integrative AI](https://aclanthology.org/2024.emnlp-demo.2.pdf) | - | emnlp 2024 | [Github](https://github.com/microsoft/i-Code/tree/main/i-Code-Studio) |
| [Masked Autoencoders that Listen](https://openreview.net/forum?id=MAMOi89bOL) | - | NeurIPS 2022 | [Github](https://github.com/facebookresearch/AudioMAE) |
| [An Introduction to Adversarially Robust Deep Learning](https://ieeexplore.ieee.org/document/10313059) | - | TPAMI 2024 | - |
| [AnyGPT: Unified Multimodal LLM with Discrete Sequence Modeling](https://aclanthology.org/2024.acl-long.521/) | - | 2024.acl-long  | [Github](https://github.com/OpenMOSS/AnyGPT) |
| [Robust Self-Supervised Audio-Visual Speech Recognition](https://arxiv.org/abs/2201.01763) | - | 	Interspeech 2022 | [Github](https://github.com/facebookresearch/av_hubert) |
| [InternVideo2: Scaling Foundation Models for Multimodal Video Understanding](https://arxiv.org/abs/2403.15377) | - | ECCV2024 | [Github](https://github.com/OpenGVLab/InternVideo/tree/main/InternVideo2/) |
| [Regeneration Learning: A Learning Paradigm for Data Generation](https://arxiv.org/abs/2301.08846) | - | AAAI 2024 | - |
| [X-LLM: Bootstrapping Advanced Large Language Models by Treating Multi-Modalities as Foreign Languages](https://arxiv.org/abs/2305.04160) | - | arXiv May 2023 | [Github](https://github.com/phellonchen/x-llm)|
| [SpeechGPT: Empowering Large Language Models with Intrinsic Cross-Modal Conversational Abilities](https://arxiv.org/abs/2305.11000) | - | arXiv May 2023  | [Github](https://github.com/0nutation/SpeechGPT) |
| [GaussianTalker: Real-Time High-Fidelity Talking Head Synthesis with Audio-Driven 3D Gaussian Splatting](https://arxiv.org/abs/2404.16012) | - | ACM MM 2024 | [Github](https://github.com/cvlab-kaist/GaussianTalker) |
| [Generating Holistic 3D Human Motion from Speech](https://openaccess.thecvf.com/content/CVPR2023/papers/Yi_Generating_Holistic_3D_Human_Motion_From_Speech_CVPR_2023_paper.pdf) | - |  CVPR2023 | - |
| [HeadStudio: Text to Animatable Head Avatars with 3D Gaussian Splatting](https://www.ecva.net/papers/eccv_2024/papers_ECCV/papers/04681.pdf) | - | ECCV 2024 | [Github](https://github.com/zhenglinzhou/headstudio) |
| [SHOW in Generating Holistic 3D Human Motion from Speech](https://openaccess.thecvf.com/content/CVPR2023/papers/Yi_Generating_Holistic_3D_Human_Motion_From_Speech_CVPR_2023_paper.pdf) | - | CVPR 2023 | [Github](https://github.com/yhw-yhw/show) |
| [TalkSHOW: Generating Holistic 3D Human Motion from Speech](https://openaccess.thecvf.com/content/CVPR2023/papers/Yi_Generating_Holistic_3D_Human_Motion_From_Speech_CVPR_2023_paper.pdf) | - | CVPR2023 | [Github](https://github.com/yhw-yhw/talkshow) |
| [Conformers are All You Need for Visual Speech Recognition](https://ieeexplore.ieee.org/document/10446532) | - |  ICASSP 2024 | - |
| [DiffMotion: Speech-Driven Gesture Synthesis Using Denoising Diffusion Model](https://link.springer.com/chapter/10.1007/978-3-031-27077-2_18)| - | MMM 2023 | - |
| [Molmo and PixMo: Open Weights and Open Data for State-of-the-Art Vision-Language Models](https://arxiv.org/abs/2409.17146)| - | arXiv Dec 2024 | [Github](https://github.com/allenai/molmo)|
| [i-Code V2: An Autoregressive Generation Framework over Vision, Language, and Speech Data](https://aclanthology.org/2024.findings-naacl.105/) | - | 2024.findings-naacl | - |
| [FINE-GRAINED AUDIO-VISUAL JOINT REPRESENTATIONS FOR MULTIMODAL LARGE LANGUAGE MODELS](https://openreview.net/forum?id=wD8L86iCvD) | - | ICLR 2024 | [Github](https://github.com/the-anonymous-bs/av-SALMONN) |
